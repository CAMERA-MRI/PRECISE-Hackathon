{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP3b85Nd9pDj"
      },
      "source": [
        "### Importing Datasets and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzwpytsyAMMP",
        "outputId": "1a18f59b-2d7e-4a3f-fab7-3fe37297fb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m41.0/46.0 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m721.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install torchcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXh3sD2wIWBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefed780-1d8c-4736-9616-fa79fe577f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m292.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oen-ZYK1r_le"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchcam.methods import GradCAM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown -q 1g61gMabSflHdZzlQ5o6KUq5hpmIYZJI4 # Download PRECISE Hack Dataset\n",
        "!unzip -q /content/PRECISE_Hackathon_Dataset.zip # Unzip Dataset\n",
        "!rm -rf /content/PRECISE_Hackathon_Dataset.zip"
      ],
      "metadata": {
        "id": "9B72t-iCUL2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Masks, Prep Classification Dataset\n",
        "data_path = '/content/PRECISE_Hackathon_Dataset'\n",
        "\n",
        "for root, dir, img in os.walk(data_path):\n",
        "  for image in img:\n",
        "    if 'mask' in image:\n",
        "      os.remove(os.path.join(root, image))"
      ],
      "metadata": {
        "id": "CDuPGduZf3hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown -q 1XqyPeOKnoXX5e_BlgFkZqj4eGtSh1ixf # Download Swin Classification Model"
      ],
      "metadata": {
        "id": "Kb1ccGuFhfIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9Ghrxfe_4QN"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/content/Breast-US-Model.pth', map_location=torch.device('cpu'), weights_only = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FLcDEQB_zzu"
      },
      "source": [
        "### Explainability Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzVkizY3KhUj"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "target_layer = model.features[7]\n",
        "target_layer.requires_grad_(True)\n",
        "cam_extractor_C = GradCAM(model, target_layer)\n",
        "\n",
        "def preprocess_image(Input_Image):\n",
        "  transform = transforms.Compose([\n",
        "        transforms.Resize(320),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
        "\n",
        "  return transform(Input_Image).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_2rr-wdISWw"
      },
      "source": [
        "### Gradio Launcher"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_visualize(Input_Image):\n",
        "    input_tensor = preprocess_image(Input_Image)\n",
        "    Class_Output = model(input_tensor)\n",
        "    probabilities = torch.sigmoid(Class_Output)\n",
        "\n",
        "    # Calculate confidence scores for all three classes\n",
        "    confidence_benign = float(probabilities[0][0])\n",
        "    confidence_malignant = float(probabilities[0][1])\n",
        "    confidence_normal = float(probabilities[0][2])\n",
        "\n",
        "    confidences = {\n",
        "        \"Benign\": confidence_benign,\n",
        "        \"Malignant\": confidence_malignant,\n",
        "        \"Normal\": confidence_normal\n",
        "    }\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class_idx = probabilities.argmax(dim=1).item()\n",
        "\n",
        "    class_names = [\"Benign\", \"Malignant\", \"Normal\"]\n",
        "    predicted_class = class_names[predicted_class_idx]\n",
        "\n",
        "    # Generate activation map\n",
        "    activation_map = cam_extractor_C(predicted_class_idx, Class_Output)\n",
        "\n",
        "    # Process the image and heatmap\n",
        "    img_array = np.array(Input_Image.convert('RGB'))\n",
        "    img_array = cv2.resize(img_array, (224, 224))\n",
        "    heatmap = activation_map[0].squeeze().numpy()\n",
        "    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.resize(heatmap, (img_array.shape[1], img_array.shape[0]))\n",
        "\n",
        "    if img_array.shape == heatmap.shape:\n",
        "        superimposed_img = cv2.addWeighted(img_array, 0.6, heatmap, 0.4, 0)\n",
        "    else:\n",
        "        raise ValueError(\"The dimensions or the number of channels of the images do not match.\")\n",
        "\n",
        "    superimposed_img = Image.fromarray(superimposed_img)\n",
        "\n",
        "    return confidences, predicted_class, superimposed_img"
      ],
      "metadata": {
        "id": "3clOFISdk8fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G7bxH8dTi_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "8ba27a34-5ea0-4d6b-d142-d95b47ef260c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://1ac3d1b3a0b67ec639.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1ac3d1b3a0b67ec639.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1ac3d1b3a0b67ec639.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Gradio Interface\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "examples = ['/content/PRECISE_Hackathon_Dataset/benign/benign (101).png',\n",
        "            '/content/PRECISE_Hackathon_Dataset/benign/benign (17).png',\n",
        "            '/content/PRECISE_Hackathon_Dataset/malignant/malignant (106).png',\n",
        "            '/content/PRECISE_Hackathon_Dataset/malignant/malignant (168).png',\n",
        "            '/content/PRECISE_Hackathon_Dataset/normal/normal (101).png',\n",
        "            '/content/PRECISE_Hackathon_Dataset/normal/normal (17).png'\n",
        "            ]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_and_visualize,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3),\n",
        "        gr.Image(label=\"Grad-CAM Visualisation\", type=\"pil\")\n",
        "    ],\n",
        "\n",
        "    title=\"Breast Cancer Classification with Grad-CAM Visualization\",\n",
        "    description=\"Upload an Image to Classify as Positive or Negative for Breast Cancer Proliferation.\",\n",
        "    examples = examples\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l6lGEIlUmiI1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}